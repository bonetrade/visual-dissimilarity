{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AehLane/BoneTrade-Project-OSLNN/blob/master/Human_Remains_OSLNN_Triplet_Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWeTgO_e6Y9e"
   },
   "source": [
    "# Visual Dissimilarity \n",
    "\n",
    "Original code framework adapted by Alex Lane from Harshvardhan Gupta, 2017 [One Shot Learning With Siamese Networks](https://github.com/harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch/blob/master/Siamese-networks-medium.ipynb) with code snippets from Tim Sherrat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-NpFQc_kHXx"
   },
   "source": [
    "---\n",
    "\n",
    "## Foundational Resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhFgO89cOLWU"
   },
   "source": [
    "For **novice users** new to data science or Google Colab, below are several links to resources hosted by 3rd parties that may help provide additional information or how-to instructions relevant to this Colab Notebook.*\n",
    "\n",
    "Google Colaboratory:\n",
    "*   Google's [\"Welcome to Colaboratory\"](https://colab.research.google.com/notebooks/welcome.ipynb)\n",
    "*   [Google Colaboratory FAQ](https://research.google.com/colaboratory/faq.html)\n",
    "*   Anne Bonner, 2019 [Getting Started With Google Colab, A Simple Tutotial for the Frustrated and Confused](https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c)\n",
    "*   Jason Richards, 2019 [Getting Local with Google Colab](https://medium.com/@jasonrichards911/getting-local-with-google-colab-a4d69f373364)\n",
    "\n",
    "Tensorflow & PyTorch:\n",
    "*   Jake VanderPlas, 2019 [Get started with Google Colaboratory (Coding TensorFlow)](https://www.youtube.com/watch?v=inN8seMm7UI&ab_channel=TensorFlow)\n",
    "*   Dr. Joanne Kitson, 2019 [Installing Tensorflow with CUDA, cuDNN and GPU support on Windows 10](https://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781)\n",
    "*   Oliver Moindrot, 2018 [Triplet Loss and Online Triplet Mining in Tensorflow](https://omoindrot.github.io/triplet-loss)\n",
    "*   Joakim Rishaug, 2020 [PyTorch Conversion of Triplet Loss and Online Triplet Mining](https://github.com/NegatioN/OnlineMiningTripletLoss)\n",
    "\n",
    "Neural Networks & Data Science:\n",
    "*   Harshvardhan Gupta, 2017 [One Shot Learning With Siamese Networks](https://github.com/harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch/blob/master/Siamese-networks-medium.ipynb)\n",
    "*   Will Koehrsen, 2018 [Neural Networks Embeddings Explained](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)\n",
    "*   Sagar Sharma, 2017 [Epoch vs Batch Size vs Iterations](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)\n",
    "*   Raúl Gómez, 2019 [Understanding Ranking Loss, Contrastive Loss, Margin Loss, Triplet Loss, Hinge Loss and all those confusing names](https://gombru.github.io/2019/04/03/ranking_loss/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*We do not guarantee the quality of the content hosted by these 3rd parties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30S_KDoFnjZA"
   },
   "source": [
    "---\n",
    "## Running this Notebook in Hosted vs. Local Runtime Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8a5zBpaeOQNP"
   },
   "source": [
    "We are assuming you have loaded this notebook with Google Colab and that you are signed into a Google account. \n",
    "\n",
    "For the first time through, you will run each block of code in sequential order. If after having trained a network you wish to resume testing at a later date, we will show you how to save your model and reload it, at the appropriate blocks.\n",
    "\n",
    "By **default**, we are assuming **you will be using Colab's hosted runtime environment**, but if you have access to a server/cluster that you would prefer to use instead, or would prefer to run it locally on the machine that has loaded up this Colab notebook, read on:\n",
    "\n",
    "\n",
    "*   If you want to run this notebook in a **local environment on the machine that has loaded up this Colab notebook** or if you are using **Google's Compute Engine**, you can find instructions [here](https://research.google.com/colaboratory/local-runtimes.html)\n",
    "\n",
    "*   If you are looking to **run this notebook on another machine** and are **not** using **Google Compute Engine**, the following instructional guidelines may be of use to you.*\n",
    "\n",
    "*This is just how we have been running our local server instance. No guarantee it will work exactly as described for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wF6fSt91yfkV"
   },
   "source": [
    "### Our Server Settings and Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8UQI0-cP0LS"
   },
   "source": [
    "Server OS: Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-74-generic x86_64)\n",
    "\n",
    "GPU: Tesla V100-PCIE-16GB\n",
    "\n",
    "Compute capability: 7.0\n",
    "\n",
    "CUDA Toolkit: 10.1\n",
    "\n",
    "CuDnn: v7.6.5 for CUDA 10.1\n",
    "\n",
    "Python: 3.6.9\n",
    "\n",
    "Tensorflow: 2.1.0\n",
    "\n",
    "PyTorch: 1.4.0\n",
    "\n",
    "Jupyter Notebook: 6.0.3\n",
    "\n",
    "Additional libraries needed: imgaug, matplotlib, [online_triplet_loss](https://github.com/NegatioN/OnlineMiningTripletLoss) (can be installed through pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wswve6o7yrMX"
   },
   "source": [
    "### Steps We Use to Connect to Our Server for Local Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWUcnG2fP6w6"
   },
   "source": [
    "1.   Open cmd prompt on the machine with the open Colab notebook.\n",
    "2. Create a port tunnel using ssh, so choose an open port on both the client and server side; `local_port` & `server_port`.\n",
    "3.   Choose one:\n",
    "\n",
    "    3a. If the server asks for a password on ssh connection `ssh -L localhost:local_port:localhost:server_port username:password@server_IP`.\n",
    "\n",
    "    3b.If the server asks for a password after ssh connection `ssh -L localhost:local_port:localhost:server_port username@server_IP`.\n",
    "4. Start the Jupyter notebook on the server_port chosen `jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --NotebookApp.port_retries=0 --notebook-dir=\"\" --no-browser --allow-root --NotebookApp.token='' --NotebookApp.disable_check_xsrf=True --port=server_port`.\n",
    "5. On another tab of the client side browser, check `localhost:local_port` to make sure the notebook has been correctly port forwarded.\n",
    "6. Select the drop-down menu for Colab runtimes in the top right of the notebook UI, 'Connect'.\n",
    "7. Select 'Connect to local runtime'.\n",
    "8. Enter `http://localhost:local_port/` into the pop-up window and select the 'Connect' button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5oU-S9i-mkz"
   },
   "source": [
    "---\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PmuK5hwAOS01"
   },
   "source": [
    "These imported libraries are required to build the neural network, define our loss function, and display the results in the 'Testing' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7l92t8_-FOeK"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the online mining triplet loss method outlined below\n",
    "# https://www.jrishaug.com/OnlineMiningTripletLoss/\n",
    "!pip install online_triplet_loss\n",
    "from online_triplet_loss.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpQfE1qVFUVW"
   },
   "source": [
    "---\n",
    "## Hardware Acceleration (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14xNGDcFOV2U"
   },
   "source": [
    "Under 'Edit' -> 'Notebook Settings' make sure to select 'GPU' for Hardware Acceleration. This block of code confirms that a GPU has been selected for  Tensorflow and PyTorch operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjVyWDJAF4-m"
   },
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egql6oG4BGpk"
   },
   "source": [
    "---\n",
    "## Loading Data for Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOzC8F7kOZ2f"
   },
   "source": [
    "**By default, we expect the data to be stored as a compressed .zip directory with the following structure:**\n",
    "\n",
    "    data.zip/\n",
    "    |----testing/\n",
    "    |    |----test_img_1\n",
    "    |    |    |----test_img_1.png\n",
    "    |    |----test_img_2\n",
    "    |    |    |----test_img_2.png\n",
    "    |    |----test_img_3\n",
    "    |    |    |----test_img_3.png\n",
    "    |    |----...\n",
    "    |----training/\n",
    "    |    |----train_img_1/\n",
    "    |    |    |----train_img_1_augmented_variation_1.png\n",
    "    |    |    |----train_img_1_augmented_variation_2.png\n",
    "    |    |    |----train_img_1_augmented_variation_3.png\n",
    "    |    |    |----...\n",
    "    |    |----train_img_2/\n",
    "    |    |    |----train_img_2_augmented_variation_1.png\n",
    "    |    |    |----train_img_2_augmented_variation_2.png\n",
    "    |    |    |----train_img_2_augmented_variation_3.png\n",
    "    |    |    |----...\n",
    "    |    |----train_img_3/\n",
    "    |    |    |----train_img_3_augmented_variation_1.png\n",
    "    |    |    |----train_img_3_augmented_variation_2.png\n",
    "    |    |    |----train_img_3_augmented_variation_3.png\n",
    "    |    |    |----...\n",
    "\n",
    "The methods to upload the data into this notebook depend upon the runtime environment type chosen; hosted runtime or local runtime. Both hosted and local runtimes have their own instructions and associated code outlined below in their respective following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jrQFGF1T8wgI"
   },
   "source": [
    "### Load Data (Hosted Runtime)\n",
    "\n",
    "Loading data for a hosted runtime may be done by uploading the zipped data folder directly or via a Google Drive account which contains the 'data.zip' by mounting the account.\n",
    "\n",
    "**To upload directly**, open the tray at left by clicking on the `>` button. Select 'Files' and then 'Upload'. Then, select a zip file in the file explorer from the local machine. If the tray does not refresh automatically, hit 'refresh' to update the tray to show changes.\n",
    "\n",
    "Unzip the data by running the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byy27-Z_EHgx"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!unzip data.zip -d data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cp4KELeH9wcp"
   },
   "source": [
    " **To mount Google Drive**, run the next block of code. The results block will display a URL. Click on this URL, and a new window will open asking for confirmation to connect Google Drive by allowing the listed permissions. Once confirmed, an authorization code will be displayed. Copy this code, and paste into the results block below. If all goes well, the results block will shortly display the text, 'Mounted at /content/drive'. Refresh the files pane in the tray at left.\n",
    "\n",
    "If the Colab Notebook successfully connected to the Google Drive account, it will appear as a folder within the tray. To change the location in the tray Google Drive is mounted, right-click on a folder within Google Drive, copy the path, and then paste that into the code below. **Note**: The leading `/content/` may need to be deleted from the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ne9mUU_TQFLJ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ft2c2VM-Zx7"
   },
   "source": [
    "The code cell below shows how to copy a file from Google Drive to this space, and then unzip the folder. It may be required that the path specified below is modified so it properly details the location of the unzipped data directory. Optionally, uncommenting `!mkdir data && unzip data.zip -d data/` will create a new directory to contain the unzipped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0rfcjBnQbVg"
   },
   "outputs": [],
   "source": [
    "# If you have data already on google drive\n",
    "!cp \"drive/My Drive/one-shot-test/data.zip\" data.zip\n",
    "\n",
    "# !mkdir data && unzip data.zip -d data/\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRgIwYGu9qV_"
   },
   "source": [
    "### Load Data (Local Runtime)\n",
    "\n",
    "Loading data for a local runtime may be performed by the following code cell which will unzip the data folder. Optionally, it is possible to specify the path to the 'data.zip' below, ie. `path/to/your/data.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvPOjTc6dgWZ"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# https://thispointer.com/python-how-to-unzip-a-file-extract-single-multiple-or-all-files-from-a-zip-archive/\n",
    "# Create a ZipFile Object and load sample.zip in it\n",
    "with ZipFile('data.zip', 'r') as zipObj:\n",
    "    # Extract all the contents of zip file in current directory\n",
    "    zipObj.extractall('data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0yyYaOq-031"
   },
   "source": [
    "---\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoM6A3GfOclN"
   },
   "source": [
    "Three helper functions, `imshow` and `show_plot`, and `worker_init_fn`, are defined here to assist in parallelizing or displaying results in later sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gE-TfRPnGGxd"
   },
   "outputs": [],
   "source": [
    "# Is called when we want to show our compared images in the testing output\n",
    "def imshow(img, text=None, text2=None, should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(\n",
    "            10, 10, text, style='italic', fontweight='bold',\n",
    "            bbox={'facecolor': 'white', 'alpha': 0.8, 'pad': 10})\n",
    "    if text2:\n",
    "        plt.text(\n",
    "            120, 10, text2, style='italic', fontweight='bold',\n",
    "            bbox={'facecolor': 'white', 'alpha': 0.8, 'pad': 10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Simple display function used to show loss during training\n",
    "def show_plot(iteration, loss):\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4OMg3RNu-QsV"
   },
   "source": [
    "### Defining Dataloader Workers' init()\n",
    "\n",
    "This function, `worker_init_fn` allows splitting the task of generating image pairs among a group of workers. This function is provided as an argument for `DataLoader` class types, giving the dataloader an init method for its workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dv5acBUGTpr"
   },
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "    dataset = worker_info.dataset\n",
    "\n",
    "    dataset.worker_unique_id = worker_info.id\n",
    "    dataset.number_of_workers = worker_info.num_workers\n",
    "    dataset.reference_iter_index = torch.tensor(worker_info.id)\n",
    "    dataset.unknown_iter_index = torch.tensor(worker_info.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54yR3gxVEp3c"
   },
   "source": [
    "---\n",
    "##Custom Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xd_BB_fPOf0L"
   },
   "source": [
    "Custom class definitions including the `Config` class, `SiameseNetworkDataset` classes, and our neural network's `SiameseNetwork` class are defined here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hh2Y_l8_bpY"
   },
   "source": [
    "### Configuration Class\n",
    "\n",
    "The 'Config' class defines variables that will be reused throughout later sections.\n",
    "\n",
    "You may want to change some of these variables to work for your purposes.\n",
    "\n",
    "Refer to the **'Loading Data' section for guidelines** for directory structure for the loaded data.\n",
    "\n",
    "`training_dir = path/to/your/data/training`\n",
    "\n",
    "`testing_dir = path/to/your/data/testing`\n",
    "\n",
    "`num_generator_workers = desired_number_of_parallel_workers`*\n",
    "\n",
    "*Currently, Python's multiprocessing, Dataloaders, and our selected method of training are not fully compatible with each other which is why the `num_generator_workers` equals 0 by default to avoid unhandled runtime errors due to workers unexpectedly exiting. As this may behaviour may change in the future, we are keeping it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwjIJqCwdy_w"
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    training_dir = \"data/training\"\n",
    "    testing_dir = \"data/testing\"\n",
    "    train_batch_size = 32\n",
    "    train_number_epochs = 200\n",
    "    num_generator_workers = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RC_2Oc5L_8V4"
   },
   "source": [
    "### Custom Dataset Classes\n",
    "\n",
    "Under a superclass of `SiameseNetworkDataset`, three subclasses exist for different purposes; one for training and two for testing.\n",
    "\n",
    "**For training**, using `BatchTripletSiameseNetworkDataset`, returns a valid triplet with an anchor image, positive image of the same class as the anchor, and a negative image of a different class as the anchor.\n",
    "\n",
    "\n",
    "**For testing**, `TestingSiameseNetworkDatasetReferences`' `__getitem__` method returns a valid reference image while `TestingSiameseNetworkDatasetUnknowns`' `__getitem__` method returns a valid unknown together forming a valid reference-unknown pair of images. Since the data is kept as a generator due to possibly working with large sets of data, the runtime should be __O(n^2)__ in the 'Testing' section due to iteratively comparing each element of the dataset to each potential pair member in the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C49BrRm0GdTY"
   },
   "outputs": [],
   "source": [
    "# Our base class for all training & testing dataset classes\n",
    "class SiameseNetworkDataset(Dataset):\n",
    "\n",
    "    def __init__(self, imageFolderDataset, transform=None, should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset\n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)\n",
    "\n",
    "\n",
    "# This simple class retrieves a random image. During training, using\n",
    "# online_triplet_mining, we'll select valid triplets for training from the set\n",
    "# of random images this generates.\n",
    "class BatchTripletSiameseNetworkDataset(SiameseNetworkDataset):\n",
    "\n",
    "    # Returns an random image from our training data\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        randIndex = random.randrange(0, len(self.imageFolderDataset.imgs))\n",
    "        img0_tuple = self.imageFolderDataset.imgs[randIndex]\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img0 = img0.convert(\"L\")\n",
    "\n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "\n",
    "        return (img0,\n",
    "                img0_tuple)\n",
    "\n",
    "\n",
    "# During testing, we'll use this class to find reference images in the data.\n",
    "# These references are found using the 'reference_file_indentifier', checking\n",
    "# the data directory for file names containing 'reference_file_identifier'.\n",
    "class TestingSiameseNetworkDatasetReferences(SiameseNetworkDataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            imageFolderDataset,\n",
    "            transform, should_invert,\n",
    "            reference_iter_index,\n",
    "            unknown_iter_index=0,\n",
    "            reference_file_identifier='',\n",
    "            worker_unique_id=0,\n",
    "            number_of_workers=1):\n",
    "        super().__init__(imageFolderDataset, transform, should_invert)\n",
    "        self.reference_iter_index = reference_iter_index\n",
    "        self.unknown_iter_index = unknown_iter_index\n",
    "        self.reference_file_identifier = reference_file_identifier\n",
    "        self.worker_unique_id = worker_unique_id\n",
    "        self.number_of_workers = number_of_workers\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        while self.reference_iter_index < len(self):\n",
    "            if (\n",
    "                    self.reference_file_identifier\n",
    "                    in\n",
    "                    self.imageFolderDataset.imgs[self.reference_iter_index][0]\n",
    "                    ):\n",
    "                reference_tuple = (\n",
    "                    self.imageFolderDataset.imgs[self.reference_iter_index])\n",
    "                break\n",
    "            else:\n",
    "                self.reference_iter_index += self.number_of_workers\n",
    "\n",
    "        if self.reference_iter_index >= len(self):\n",
    "            return -1, -1, -1, -1, -1, -1\n",
    "        else:\n",
    "            self.reference_iter_index += self.number_of_workers\n",
    "            reference_image = Image.open(reference_tuple[0])\n",
    "            reference_image = reference_image.convert(\"L\")\n",
    "\n",
    "            if self.should_invert:\n",
    "                reference_image = PIL.ImageOps.invert(reference_image)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                reference_image = self.transform(reference_image)\n",
    "\n",
    "            return (self.reference_iter_index-self.number_of_workers,\n",
    "                    self.worker_unique_id,\n",
    "                    reference_image,\n",
    "                    -1,\n",
    "                    reference_tuple[0],\n",
    "                    -1)\n",
    "\n",
    "\n",
    "# During testing, we'll use this class to retrieve specified \"unknowns\" for our\n",
    "# reference-unknown pairs.\n",
    "class TestingSiameseNetworkDatasetUnknowns(SiameseNetworkDataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            imageFolderDataset, transform, should_invert,\n",
    "            reference_iter_index, unknown_iter_index=0,\n",
    "            reference_file_identifier='',\n",
    "            worker_unique_id=0,\n",
    "            number_of_workers=1):\n",
    "        super().__init__(imageFolderDataset, transform, should_invert)\n",
    "        self.reference_iter_index = reference_iter_index\n",
    "        self.unknown_iter_index = unknown_iter_index\n",
    "        self.reference_file_identifier = reference_file_identifier\n",
    "        self.worker_unique_id = worker_unique_id\n",
    "        self.number_of_workers = number_of_workers\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        reference_tuple = (\n",
    "            self.imageFolderDataset.imgs[self.reference_iter_index])\n",
    "\n",
    "        while self.unknown_iter_index < len(self):\n",
    "            if (\n",
    "                    self.reference_file_identifier\n",
    "                    in self.imageFolderDataset.imgs[self.unknown_iter_index][0]\n",
    "                    ):\n",
    "                self.unknown_iter_index += self.number_of_workers\n",
    "            else:\n",
    "                unknown_tuple = (\n",
    "                    self.imageFolderDataset.imgs[self.unknown_iter_index])\n",
    "                break\n",
    "\n",
    "        if self.unknown_iter_index >= len(self):\n",
    "            return -1, self.worker_unique_id, -1, -1, -1, -1\n",
    "        else:\n",
    "            self.unknown_iter_index += self.number_of_workers\n",
    "\n",
    "            reference_image = Image.open(reference_tuple[0])\n",
    "            unknown_image = Image.open(unknown_tuple[0])\n",
    "            reference_image = reference_image.convert(\"L\")\n",
    "            unknown_image = unknown_image.convert(\"L\")\n",
    "\n",
    "            if self.should_invert:\n",
    "                reference_image = PIL.ImageOps.invert(reference_image)\n",
    "                unknown_image = PIL.ImageOps.invert(unknown_image)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                reference_image = self.transform(reference_image)\n",
    "                unknown_image = self.transform(unknown_image)\n",
    "\n",
    "            return (self.unknown_iter_index,\n",
    "                    self.worker_unique_id,\n",
    "                    reference_image,\n",
    "                    unknown_image,\n",
    "                    reference_tuple[0],\n",
    "                    unknown_tuple[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WoUIsQJ5BpZp"
   },
   "source": [
    "### Neural Network Class\n",
    "\n",
    "Defined below is a standard convolutional neural network. Each convolutional layer has batch normalisation and then dropout. As Gupta says, 'There is nothing special about this network. It accepts an input of 100px by 100px and has 3 full connected layers after the convolution layers'. Optionally, to further experiment, adding or modifying of layers may be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GnJJ-CSe9VS"
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*100*100, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, Config.train_batch_size)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2, training=True):\n",
    "        if training:\n",
    "            output1 = self.forward_once(input1)\n",
    "            return output1\n",
    "        else:\n",
    "            output1 = self.forward_once(input1)\n",
    "            output2 = self.forward_once(input2)\n",
    "            return output1, output2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6k0ZQeUoA3-C"
   },
   "source": [
    "---\n",
    "## Setting Up the Training Dataset and Associated Image Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nug_t0SYOij_"
   },
   "source": [
    "The location of the training data is set below to the variable defined by 'Config'. In the second block, the images are provided as a parameter to the custom dataset class, `BatchTripletSiameseNetworkDataset`, which resizes them to 100 x 100 pixels and transforming them into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gAhHc3_A3ED"
   },
   "outputs": [],
   "source": [
    "folder_dataset = dset.ImageFolder(root=Config.training_dir)\n",
    "# print(folder_dataset.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PqQBMCGIKdsS"
   },
   "outputs": [],
   "source": [
    "training_siamese_dataset = BatchTripletSiameseNetworkDataset(\n",
    "    imageFolderDataset=folder_dataset,\n",
    "    transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                  transforms.ToTensor()]),\n",
    "    should_invert=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_KJxHsaBfU0"
   },
   "source": [
    "---\n",
    "## Visualising the Training Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDhUGgb6OlGs"
   },
   "source": [
    "This displays a couple of batches of data from which the loss function may create triplets through online mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVBSCKdIKhFz"
   },
   "outputs": [],
   "source": [
    "vis_dataloader = DataLoader(\n",
    "    training_siamese_dataset, shuffle=True, num_workers=1, batch_size=16)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "example_batch_img, example_batch_names = next(dataiter)\n",
    "example_batch_img2, example_batch_names2 = next(dataiter)\n",
    "concatenated = torch.cat((example_batch_img, example_batch_img2), 0)\n",
    "concatenated_names = torch.cat((\n",
    "    example_batch_names[1], example_batch_names2[1]), 0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(\"Class labels:\")\n",
    "print(concatenated_names.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYNqH02sHdlU"
   },
   "source": [
    "---\n",
    "## Create or Load a Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeBJupWMOn2X"
   },
   "source": [
    "Here, a new neural network model can be trained from scratch, or alternatively skip ahead to upload a pre-existing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFjQUx_QeJRn"
   },
   "source": [
    "### Training a New Neural Network Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvkdGeL3QFNx"
   },
   "source": [
    "#### Setting Up the Network for Training\n",
    "\n",
    "The next three blocks configure all of the variables and settings for training the neural network. Optionally, the values of the Adam optimizer may be tweaked for further experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Or4xt6VDKp2H"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    training_siamese_dataset,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_generator_workers,\n",
    "    batch_size=Config.train_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnRiUE3nKuqe"
   },
   "outputs": [],
   "source": [
    "net = SiameseNetwork().cuda()\n",
    "net = net.to(device)\n",
    "criterion = batch_hard_triplet_loss\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00006)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04O3bd3SCiXG"
   },
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = []\n",
    "iteration_number = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7YqWETMC1Zl"
   },
   "source": [
    "#### Training the Neural Network\n",
    "\n",
    "This next block will start the training for the number of epochs set at the start of the notebook in the configuration block. The code is slightly modified so that filenames get stored for the images. The loss function used for training is [online_triplet_loss](https://github.com/NegatioN/OnlineMiningTripletLoss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fA0y-hd7K5et"
   },
   "outputs": [],
   "source": [
    "batch_generator = iter(train_dataloader)\n",
    "for epoch in range(0, Config.train_number_epochs):\n",
    "    batch_tensor = torch.Tensor(0, Config.train_batch_size).to(device)\n",
    "    batch_labels = torch.Tensor(0,).to(device)\n",
    "    selected_images = []\n",
    "    while(True):\n",
    "        # https://github.com/amdegroot/ssd.pytorch/issues/214\n",
    "        try:\n",
    "            potential_batch_sample, potential_name = next(batch_generator)\n",
    "        except StopIteration:\n",
    "            batch_generator = iter(train_dataloader)\n",
    "            potential_batch_sample, potential_name = next(batch_generator)\n",
    "        if (potential_name[0] in selected_images):\n",
    "            continue\n",
    "        else:\n",
    "            selected_images.append(potential_name[0])\n",
    "\n",
    "            batch_sample = potential_batch_sample\n",
    "            batch_sample = batch_sample.cuda()\n",
    "\n",
    "            potential_name = potential_name[1].cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_sample_embed = net(batch_sample, _)\n",
    "\n",
    "            batch_tensor = torch.cat((batch_tensor, batch_sample_embed), 0)\n",
    "            batch_labels = torch.cat((\n",
    "                batch_labels, potential_name.float()), 0)\n",
    "            break\n",
    "\n",
    "    batch_tensor = batch_tensor.cuda()\n",
    "    batch_labels = batch_labels.to(device)\n",
    "    hard_triplet_loss = criterion(\n",
    "        batch_labels, batch_tensor, margin=2.0, device=device)\n",
    "    hard_triplet_loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Epoch number {}\\n Current loss {}\\n\".format(\n",
    "        epoch,\n",
    "        hard_triplet_loss.item()))\n",
    "    iteration_number += 1\n",
    "    counter.append(iteration_number)\n",
    "    loss_history.append(hard_triplet_loss.item())\n",
    "show_plot(counter, loss_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKVPWER5DJVS"
   },
   "source": [
    "### Saving the Neural Network Model & State Dictionary\n",
    "\n",
    "The block below saves the state dictionary, and the model. Then, it is possible to return to it if the notebook connection to Colab is broken, or if the project is set aside for a time. The second block copies `cp` the file to a location on Google drive. It is also possible to download the file to the local machine directly by right-clicking the filename in the tray at left (hit 'refresh' to update changes if the model does not at first appear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXTopDCEhyy5"
   },
   "outputs": [],
   "source": [
    "# Save the model!\n",
    "torch.save(net.state_dict(), 'net_params_new.pkl')\n",
    "torch.save(net, 'net.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2QLT90P6eNb"
   },
   "outputs": [],
   "source": [
    "cp net_params.pkl \"drive/My Drive/one-shot-test\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sizl8QETDvAg"
   },
   "source": [
    "### Loading a Neural Network Model & State Dictionary\n",
    "\n",
    "The first time through this notebook, this section is not important; skip down to 'Testing'. Otherwise, upon returning to the project make sure that **sections 'Imports' through 'Setting the image folder...' are run**.\n",
    "\n",
    "This code cell below assumes Google Drive is mounted & connected. Alternatively, a model may be directly uploaded or load a model from the local machine using the second code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCbuAtMOigQ6"
   },
   "outputs": [],
   "source": [
    "# Copy the model back from your drive\n",
    "!cp \"drive/My Drive/one-shot-test/net_params.pkl\" net_params.pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLQ_aEcCERPI"
   },
   "source": [
    "...then tell the machine to load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvKhEPhr7oqu"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "net = SiameseNetwork()\n",
    "net.load_state_dict(torch.load('net_params.pkl'))\n",
    "dp = nn.DataParallel(net)  # https://github.com/pytorch/pytorch/issues/3805\n",
    "\n",
    "# The incompatiblekeys message might not be an issue - see\n",
    "# https://gpytorch.readthedocs.io/en/latest/examples/00_Basic_Usage/Saving_and_Loading_Models.html\n",
    "# which replicates that incompatiblekeys message without any kind of comment,\n",
    "# seems to be hunkydory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LLQYb1LErDI"
   },
   "source": [
    "---\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mz1kizi0OroX"
   },
   "source": [
    "This block iteratively loads pairs of images with known provenance versus unknown provenance from different subfolders in the testing folder. It then compares the results of these reference-unknown pairs using euclidean distance. It will print out the images with the dissimilarity (euclidean distance), as well as printing out the filenames for each pair.\n",
    "\n",
    "Since this code currently outputs all possible reference-unknown pairs in the testing folder specified in `Config`, this results in the runtime being **O(n^2)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oA4QpoRCLgSK"
   },
   "outputs": [],
   "source": [
    "# Time code snippet\n",
    "# https://stackoverflow.com/questions/1557571/how-do-i-get-time-of-a-python-programs-execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Init variable representing testing data's directory, see Config section to\n",
    "# specify path.\n",
    "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "\n",
    "# Create the dataset, siamese_dataset_references, with the testing data\n",
    "# Then, create a generator with siamese_dataset_references\n",
    "siamese_dataset_references = TestingSiameseNetworkDatasetReferences(\n",
    "    imageFolderDataset=folder_dataset_test,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((100, 100)), transforms.ToTensor()]),\n",
    "    should_invert=False,\n",
    "    reference_iter_index=0,\n",
    "    reference_file_identifier='ref-')\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    siamese_dataset_references,\n",
    "    num_workers=Config.num_generator_workers,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    worker_init_fn=worker_init_fn)\n",
    "\n",
    "generator_reference_images = iter(test_dataloader)\n",
    "workers_terminated_outer = np.zeros(Config.num_generator_workers)\n",
    "\n",
    "# Outer for loop searches for references\n",
    "for i in range(len(generator_reference_images)):\n",
    "\n",
    "    # Returns a found reference's index, image, and filepath\n",
    "    (reference_index,\n",
    "        worker_id_outer,\n",
    "        reference_image,\n",
    "        _,\n",
    "        reference_filepath,\n",
    "        _) = next(generator_reference_images)\n",
    "\n",
    "    '''\n",
    "    # Stop outer loop if index is out of bounds, no more potential references\n",
    "    if not(0 in workers_terminated_outer):\n",
    "        break\n",
    "    '''\n",
    "\n",
    "    if reference_index.item() < 0:\n",
    "        '''\n",
    "        np.put(workers_terminated_outer, worker_id_outer, 1)\n",
    "        if not(0 in workers_terminated_outer):\n",
    "            break\n",
    "        '''\n",
    "        break\n",
    "    else:\n",
    "\n",
    "        # Create new dataset with a given known reference's index\n",
    "        # Then, create a generator with siamese_dataset_unknowns\n",
    "        siamese_dataset_unknowns = TestingSiameseNetworkDatasetUnknowns(\n",
    "            imageFolderDataset=folder_dataset_test,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.Resize((100, 100)), transforms.ToTensor()]),\n",
    "            should_invert=False,\n",
    "            reference_iter_index=reference_index,\n",
    "            reference_file_identifier='ref-')\n",
    "\n",
    "        compare_dataloader = test_dataloader = DataLoader(\n",
    "            siamese_dataset_unknowns,\n",
    "            num_workers=Config.num_generator_workers,\n",
    "            batch_size=1, shuffle=False,\n",
    "            worker_init_fn=worker_init_fn)\n",
    "\n",
    "        generator_unknown_prov_images = iter(compare_dataloader)\n",
    "        workers_terminated_inner = np.zeros(Config.num_generator_workers)\n",
    "\n",
    "        # Inner loop pairs reference with all images of unknown provenance\n",
    "        for k in range(len(generator_unknown_prov_images)):\n",
    "\n",
    "            # no_more_unknowns will return -1 if all pairs have been found\n",
    "            no_more_unknowns, worker_id_inner, _, unknown_prov_image, _, (\n",
    "                unknown_prov_filepath) = (next(generator_unknown_prov_images))\n",
    "\n",
    "            '''\n",
    "            # Stop this inner loop if all reference-unknown pairs for the\n",
    "            # current reference image are found\n",
    "            if not(0 in workers_terminated_inner):\n",
    "                break\n",
    "            '''\n",
    "\n",
    "            if no_more_unknowns.item() < 0:\n",
    "                '''\n",
    "                np.put(workers_terminated_inner, worker_id_inner, 1)\n",
    "                if not(0 in workers_terminated_inner):\n",
    "                    break\n",
    "                '''\n",
    "                break\n",
    "            else:\n",
    "                concatenated = torch.cat(\n",
    "                    (reference_image, unknown_prov_image), 0)\n",
    "\n",
    "                # Feed the reference-unknown pair into the neural network to\n",
    "                # return the pair's embeddings.\n",
    "                reference_embedding, unknown_embedding = net(\n",
    "                    Variable(reference_image).cuda(),\n",
    "                    Variable(unknown_prov_image).cuda(), training=False)\n",
    "\n",
    "                # Evaluate the embeddings using Euclidean distance as the\n",
    "                # metric.\n",
    "                euclidean_distance = F.pairwise_distance(\n",
    "                    reference_embedding, unknown_embedding)\n",
    "\n",
    "                # Show the images:\n",
    "                imshow(\n",
    "                    torchvision.utils.make_grid(concatenated),\n",
    "                    'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))\n",
    "\n",
    "                # Show the paths for the two images\n",
    "                print('Image 1: {}'.format(reference_filepath[0]))\n",
    "                print('Image 2: {}'.format(unknown_prov_filepath[0]))\n",
    "                print('Dissimilarity: {:.2f}'.format(\n",
    "                    euclidean_distance.item()))\n",
    "                # if you wish to write directly to file, comment out the 'Show the images' code\n",
    "                # and then modify the three print statements above along these lines:\n",
    "                # print('Image 1: {}'.format(anchor_filepath[0]), file=open('output.txt', 'a'))\n",
    "\n",
    "print('Finshed all reference-unknown pair comparisons')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVt-evEFFP62"
   },
   "source": [
    "---\n",
    "## The End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QluDMF0OvWS"
   },
   "source": [
    "The two code blocks below print out the structure of the neural network, and the version info of all of the loaded packages in this environment. This information is useful for replicating this notebook in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDnSSRJpUuzH"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = net\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2x_rKjj7UxC"
   },
   "outputs": [],
   "source": [
    "# watermark is not installed by default.\n",
    "# the first time through, uncomment the two lines below\n",
    "# then run the block.\n",
    "#\n",
    "#\n",
    "# !pip install watermark\n",
    "# %load_ext watermark\n",
    "%watermark -v -m -p numpy, scipy, torchvision, PIL, tensorflow, torch -g\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Human Remains OSLNN - Triplet Loss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
